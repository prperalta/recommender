{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c21c0d12-9868-4310-b7be-9f5eb4b63bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PyTorch Packages\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Import PyTorch Ignite\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Loss\n",
    "from ignite.metrics import MeanSquaredError\n",
    "\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fcdb5fe2-e741-47db-8e54-d4a48608a7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_users, num_items, k, c_vector,  tag_relevance_matrix=None):\n",
    "        '''\n",
    "        '''\n",
    "        super(MF, self).__init__()\n",
    "        \n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.tag_relevance_matrix = tag_relevance_matrix\n",
    "        self.k = k\n",
    "        self.gamma = self.num_users / self.num_items\n",
    "        self.c_vector = c_vector\n",
    "        \n",
    "        #initialize U and I matrices \n",
    "        self.user_embedding = nn.Embedding(num_users, k)\n",
    "        self.item_embedding = nn.Embedding(num_items, k)\n",
    "        \n",
    "        self.user_bias = nn.Embedding(num_users, 1)\n",
    "        self.item_bias = nn.Embedding(num_items, 1)\n",
    "        \n",
    "        self.user_embedding.weight.data.uniform_(0, 0.05)\n",
    "        self.item_embedding.weight.data.uniform_(0, 0.05)\n",
    "        self.user_bias.weight.data.uniform_(0.01)\n",
    "        self.item_bias.weight.data.uniform_(0.01)\n",
    "        \n",
    "    def __call__(self, train_x):\n",
    "        users = train_x[:, 0]\n",
    "        items = train_x[:, 1]\n",
    "        \n",
    "        self.users = users\n",
    "        self.items = items\n",
    "        \n",
    "        u = self.user_embedding(torch.LongTensor(users))\n",
    "        v = self.item_embedding(torch.LongTensor(items))\n",
    "        \n",
    "        #if self.tag_relevance_matrix is not None:\n",
    "        #    self.sim_mat = self.compute_cosine_similarity(torch.index_select(self.tag_relevance_matrix, 0, torch.LongTensor(items)))\n",
    "        \n",
    "        b_u = self.user_bias(torch.LongTensor(users)).squeeze()\n",
    "        b_v = self.item_bias(torch.LongTensor(items)).squeeze()\n",
    "        r_predicted = (u*v).sum(1) + b_u + b_v\n",
    "        \n",
    "        return r_predicted\n",
    "    \n",
    "    \n",
    "    def loss(self, r_hat, r):\n",
    "        loss_mse = F.mse_loss(r_hat, r)\n",
    "        \n",
    "        reg_term_users = self.l2_regularize(self.user_embedding.weight) * self.c_vector\n",
    "        reg_term_items = self.l2_regularize(self.item_embedding.weight) * self.c_vector * self.gamma\n",
    "        reg_term_user_bias = self.l2_regularize(self.user_embedding.weight) * self.c_vector\n",
    "        reg_term_item_bias = self.l2_regularize(self.item_embedding.weight) * self.c_vector * self.gamma\n",
    "        #tag_based_penalty = self.compute_tag_based_penalty(self.item_embedding, self.items, self.sim_mat)\n",
    "        \n",
    "        total_loss = loss_mse + reg_term_users + reg_term_items + reg_term_user_bias + reg_term_item_bias #+ tag_based_penalty\n",
    "        return total_loss\n",
    "    \n",
    "    \n",
    "    def l2_regularize(self, v):\n",
    "        #loss = torch.sum(v ** 2.0)\n",
    "        loss = torch.linalg.norm(v)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def compute_tag_based_penalty(self, feature_vector, index_vector, sim_mat):\n",
    "        feature_vector = feature_vector(torch.LongTensor(index_vector))\n",
    "        res = 0 \n",
    "        for i in range(0,len(index_vector)):\n",
    "            v_i = feature_vector[i]\n",
    "            for j in range(0,len(index_vector)):\n",
    "                v_j = feature_vector[j]\n",
    "                temp = v_i - v_j\n",
    "                res += torch.sum(temp**2) * sim_mat[i,j]\n",
    "                \n",
    "        return res\n",
    "        \n",
    "    def compute_cosine_similarity(self, m):\n",
    "        m_norm = m / m.norm(dim=1)[:, None]\n",
    "        res = torch.mm(m_norm, m_norm.transpose(0,1))\n",
    "        return res.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5046bd61-9dd4-4266-baed-8d182d0adb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import torch\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "# Initialize a Loader class\n",
    "class Loader():\n",
    "    # Set the iterator\n",
    "    current = 0\n",
    "\n",
    "    def __init__(self, x, y, batchsize=1024, do_shuffle=True):\n",
    "        \"\"\"\n",
    "        :param x: features\n",
    "        :param y: target\n",
    "        :param batchsize: batch size = 1024\n",
    "        :param do_shuffle: shuffle mode turned on\n",
    "        \"\"\"\n",
    "        self.shuffle = shuffle\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.batchsize = batchsize\n",
    "        self.batches = range(0, len(self.y), batchsize)\n",
    "        if do_shuffle:\n",
    "            # Every epoch re-shuffle the dataset\n",
    "            self.x, self.y = shuffle(self.x, self.y)\n",
    "\n",
    "    def __iter__(self):\n",
    "        # Reset & return a new iterator\n",
    "        self.x, self.y = shuffle(self.x, self.y, random_state=0)\n",
    "        self.current = 0\n",
    "        return self\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the number of batches\n",
    "        return int(len(self.x) / self.batchsize)\n",
    "\n",
    "    def __next__(self):\n",
    "        # Update iterator and stop iteration until the batch size is out of range\n",
    "        n = self.batchsize\n",
    "        if self.current + n >= len(self.y):\n",
    "            raise StopIteration\n",
    "        i = self.current\n",
    "\n",
    "        # Transform NumPy arrays to PyTorch tensors\n",
    "        xs = torch.from_numpy(self.x[i:i + n])\n",
    "        ys = torch.from_numpy(self.y[i:i + n])\n",
    "        self.current += n\n",
    "        return xs, ys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c366fc2-f1e8-476a-b546-b2612097b310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_training_loss(engine, log_interval=500):\n",
    "    \"\"\"\n",
    "    Function to log the training loss\n",
    "    \"\"\"\n",
    "    model.itr = engine.state.iteration  # Keep track of iterations\n",
    "    if model.itr % log_interval == 0:\n",
    "        fmt = \"Epoch[{}] Iteration[{}/{}] Loss: {:.2f}\"\n",
    "        # Keep track of epochs and outputs\n",
    "        msg = fmt.format(engine.state.epoch, engine.state.iteration, len(train_loader), engine.state.output)\n",
    "        print(msg)\n",
    "\n",
    "\n",
    "def log_validation_results(engine):\n",
    "    \"\"\"\n",
    "    Function to log the validation loss\n",
    "    \"\"\"\n",
    "    # When triggered, run the validation set\n",
    "    evaluator.run(test_loader)\n",
    "    # Keep track of the evaluation metrics\n",
    "    avg_loss = evaluator.state.metrics['evaluation']\n",
    "    print(\"Epoch[{}] Validation MSE: {:.2f} \".format(engine.state.epoch, avg_loss))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c50edaa4-2041-4376-994b-8f93bd64280a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'ml-20m'\n",
    "#genome_scores = pd.read_csv(os.path.join(path,'genome-scores.csv'))\n",
    "#genome_tags = pd.read_csv(os.path.join(path,'genome-tags.csv'))\n",
    "#tags = pd.read_csv(os.path.join(path,'tags.csv'))\n",
    "movies_full = pd.read_csv(os.path.join(path,'movies.csv'))\n",
    "ratings_full = pd.read_csv(os.path.join(path,'ratings.csv'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32ba0a49-7f1b-4043-b4ea-08572d6e1656",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paolo\\AppData\\Local\\Temp\\ipykernel_3732\\3015794648.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ratings['userId'] = ratings['userId'].apply(lambda x : userid2idx[x])\n",
      "C:\\Users\\Paolo\\AppData\\Local\\Temp\\ipykernel_3732\\3015794648.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ratings['movieId'] = ratings['movieId'].apply(lambda x : movieid2idx[x])\n",
      "C:\\Users\\Paolo\\AppData\\Local\\Temp\\ipykernel_3732\\3015794648.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  movies['movieId'] = movies['movieId'].apply(lambda x : movieid2idx[x])\n"
     ]
    }
   ],
   "source": [
    "#Pre-process\n",
    "\n",
    "#remove on deployment\n",
    "ratings = ratings_full.head(10000000)\n",
    "\n",
    "#remove movies without ratings\n",
    "movies = movies_full[movies_full['movieId'].isin(ratings['movieId'].unique())]\n",
    "\n",
    "#remap ids to continuous integers\n",
    "user_ids = np.sort(np.unique(ratings['userId']))\n",
    "userid2idx = {o:i for i,o in enumerate(user_ids) }\n",
    "\n",
    "movie_ids = np.sort(np.unique(ratings['movieId']))\n",
    "movieid2idx = {o:i for i,o in enumerate(movie_ids) }\n",
    "\n",
    "ratings['userId'] = ratings['userId'].apply(lambda x : userid2idx[x])\n",
    "ratings['movieId'] = ratings['movieId'].apply(lambda x : movieid2idx[x])\n",
    "movies['movieId'] = movies['movieId'].apply(lambda x : movieid2idx[x])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48ccb25e-fd76-4a53-b86b-88db0c98bc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#movie_tag_pair = list(product(movieid2idx.values(), tagid2idx.values()))\n",
    "#movie_tag_pair_df = pd.DataFrame(movie_tag_pair, columns =['movieId', 'tagId'])\n",
    "#m = movie_tag_pair_df.merge(genome_scores, on=['movieId','tagId'], how='left')\n",
    "#movie_tag_relevance = m.pivot_table(index='movieId', columns=['tagId'], values='relevance', dropna=False, fill_value=0)\n",
    "#movie_tag_relevance = torch.from_numpy(movie_tag_relevance.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8be52aeb-3131-4cd5-854a-b44177d454ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paolo\\AppData\\Local\\Temp\\ipykernel_22620\\769775228.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ratings['is_train'] = np.random.random(len(ratings)) < 0.95\n"
     ]
    }
   ],
   "source": [
    "# Set a random seed to make our numbers predictable\n",
    "np.random.seed(42)\n",
    "\n",
    "ratings['is_train'] = np.random.random(len(ratings)) < 0.95\n",
    "training_data = ratings[ratings['is_train']]\n",
    "test_data = ratings[~ratings['is_train']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eea03fb-ea7b-4ffe-ad2a-a6e3da4a5964",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "lr = 1e-2 \n",
    "k = 3 \n",
    "c_vector = 1e-6  \n",
    "\n",
    "# Instantiate the MF class object\n",
    "model = MF(len(user_ids), len(movie_ids), tag_relevance_matrix=None, k=k, c_vector=c_vector)\n",
    "\n",
    "# Use Adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "# Create a supervised trainer\n",
    "trainer = create_supervised_trainer(model, optimizer, model.loss)\n",
    "\n",
    "# Use Mean Squared Error as evaluation metric\n",
    "metrics = {'evaluation': MeanSquaredError()}\n",
    "\n",
    "# Create a supervised evaluator\n",
    "evaluator = create_supervised_evaluator(model, metrics=metrics)\n",
    "\n",
    "# Load the train and test data\n",
    "\n",
    "train_x = training_data[['userId', 'movieId']].values\n",
    "train_y = training_data['rating'].values.astype(np.float32)\n",
    "test_x = test_data[['userId', 'movieId']].values\n",
    "test_y = test_data['rating'].values.astype(np.float32)\n",
    "train_loader = Loader(train_x, train_y, batchsize=1024)\n",
    "test_loader = Loader(test_x, test_y, batchsize=1024)\n",
    "\n",
    "trainer.add_event_handler(event_name=Events.ITERATION_COMPLETED, handler=log_training_loss)\n",
    "trainer.add_event_handler(event_name=Events.EPOCH_COMPLETED, handler=log_validation_results)\n",
    "\n",
    "# Run the model for 50 epochs\n",
    "trainer.run(train_loader, max_epochs=50)\n",
    "\n",
    "\n",
    "# When triggered, run the validation set\n",
    "evaluator.run(test_loader)\n",
    "# Keep track of the evaluation metrics\n",
    "avg_loss = evaluator.state.metrics['evaluation']\n",
    "avg_loss\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95ad608c-17cb-43ce-8239-9bf6fd915c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = model.user_embedding \n",
    "v = model.item_embedding \n",
    "b_u = model.user_bias\n",
    "b_v = model.item_bias\n",
    "r_hat = torch.mm(u.weight, v.weight.T)\n",
    "r_pred = r_hat + b_u.weight + b_v.weight.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1bbf7efc-f4d9-4f4f-9fe8-7f1b2e01ac8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13671</th>\n",
       "      <td>13397</td>\n",
       "      <td>Days Between, The (In den Tag hinein) (2001)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18343</th>\n",
       "      <td>17477</td>\n",
       "      <td>New Life, A (La vie nouvelle) (2002)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19497</th>\n",
       "      <td>18396</td>\n",
       "      <td>Pirates of the Great Salt Lake (2006)</td>\n",
       "      <td>Adventure|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26118</th>\n",
       "      <td>22762</td>\n",
       "      <td>Always for Pleasure (1978)</td>\n",
       "      <td>(no genres listed)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26293</th>\n",
       "      <td>22809</td>\n",
       "      <td>Marihuana (1936)</td>\n",
       "      <td>Documentary|Drama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       movieId                                         title  \\\n",
       "13671    13397  Days Between, The (In den Tag hinein) (2001)   \n",
       "18343    17477          New Life, A (La vie nouvelle) (2002)   \n",
       "19497    18396         Pirates of the Great Salt Lake (2006)   \n",
       "26118    22762                    Always for Pleasure (1978)   \n",
       "26293    22809                              Marihuana (1936)   \n",
       "\n",
       "                   genres  \n",
       "13671               Drama  \n",
       "18343               Drama  \n",
       "19497    Adventure|Comedy  \n",
       "26118  (no genres listed)  \n",
       "26293   Documentary|Drama  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check recommendations\n",
    "user = 0\n",
    "user_ratings = ratings[ratings['userId']==user].sort_values(by=['rating'], ascending=False)\n",
    "user_favorites = user_ratings.head(5)\n",
    "user_favorites.merge(movies, on=['movieId'])\n",
    "user_rating = r_pred[user]\n",
    "ratings_np = user_rating.detach().numpy()\n",
    "top5_recos = np.flip(np.argsort(ratings_np))[:5]\n",
    "top5_recos\n",
    "\n",
    "not_watched = movies[~movies['movieId'].isin(user_ratings['movieId'])]\n",
    "not_watched[not_watched['movieId'].isin(top5_recos)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fb1f0f78-19b8-47d6-bd28-91e4de6f172f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7853</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1094786027</td>\n",
       "      <td>Freaks (1932)</td>\n",
       "      <td>Crime|Drama|Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4895</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1112484682</td>\n",
       "      <td>Lord of the Rings: The Fellowship of the Ring,...</td>\n",
       "      <td>Adventure|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5851</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1112484619</td>\n",
       "      <td>Lord of the Rings: The Two Towers, The (2002)</td>\n",
       "      <td>Adventure|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>7037</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1112484633</td>\n",
       "      <td>Lord of the Rings: The Return of the King, The...</td>\n",
       "      <td>Action|Adventure|Drama|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1171</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1112484742</td>\n",
       "      <td>Star Wars: Episode V - The Empire Strikes Back...</td>\n",
       "      <td>Action|Adventure|Sci-Fi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp  \\\n",
       "0       0     7853     5.0  1094786027   \n",
       "1       0     4895     5.0  1112484682   \n",
       "2       0     5851     5.0  1112484619   \n",
       "3       0     7037     5.0  1112484633   \n",
       "4       0     1171     4.5  1112484742   \n",
       "\n",
       "                                               title  \\\n",
       "0                                      Freaks (1932)   \n",
       "1  Lord of the Rings: The Fellowship of the Ring,...   \n",
       "2      Lord of the Rings: The Two Towers, The (2002)   \n",
       "3  Lord of the Rings: The Return of the King, The...   \n",
       "4  Star Wars: Episode V - The Empire Strikes Back...   \n",
       "\n",
       "                           genres  \n",
       "0              Crime|Drama|Horror  \n",
       "1               Adventure|Fantasy  \n",
       "2               Adventure|Fantasy  \n",
       "3  Action|Adventure|Drama|Fantasy  \n",
       "4         Action|Adventure|Sci-Fi  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_favorites.merge(movies, on=['movieId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891e5dbf-b4bb-4962-8b59-9aa9e1059899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to a separate folder\n",
    "torch.save(model.state_dict(), 'models/mf_k3.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
